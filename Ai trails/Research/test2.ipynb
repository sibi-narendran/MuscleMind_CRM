{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from pyprojroot import here\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import warnings\n",
    "import os\n",
    "# from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.agent_toolkits.sql.base import SQLDatabaseToolkit\n",
    "from supabase import create_client, Client\n",
    "import asyncpg\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = str(here(\"data\")) + \"/db.sqlite3\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['auth_group', 'auth_group_permissions', 'auth_permission', 'auth_user', 'auth_user_groups', 'auth_user_user_permissions', 'core_appointment', 'core_chathistory', 'core_dentist', 'core_patient', 'core_payment', 'core_treatment', 'django_admin_log', 'django_content_type', 'django_migrations', 'django_session']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'surya', 'surya@gmail.com', '07878979887', 'Orthodontist', 12, '2', '2024-11-28 05:15:35.682668'), (2, 'sibi narayanan', 'sibinarayan@gmail.com', '84329048392', 'Periodontist', 10, 'Mon, Wed, Fri', '2024-11-28 05:16:39.497547'), (3, 'yugendran', 'yugendran@gmail.com', '8943820488', 'Oral Surgeon', 9, 'Mon, Wed, Fri', '2024-11-28 05:17:19.223466'), (4, 'Lauren Lucero', 'traciprice@example.com', '(514)761-7353x00169', 'General Dentist', 2, 'Thu, Mon, Sat, Wed', '2024-11-28 06:20:33.120105'), (5, 'Cassandra Allen', 'jennifer44@example.com', '(826)692-6906', 'Pediatric Dentist', 18, 'Tue, Mon', '2024-11-28 06:20:33.120105'), (6, 'Nicholas Saunders', 'gjones@example.com', '633.378.4789', 'Periodontist', 13, 'Thu, Fri, Tue', '2024-11-28 06:20:33.120105'), (7, 'Amanda Bowman', 'christophermcbride@example.net', '742.502.6120x748', 'Prosthodontist', 16, 'Mon, Sat, Wed, Tue', '2024-11-28 06:20:33.120105'), (8, 'Elizabeth Glenn', 'rebecca76@example.org', '(430)811-7227', 'General Dentist', 4, 'Mon, Fri', '2024-11-28 06:20:33.120105'), (9, 'Alexis Faulkner', 'lucerolisa@example.org', '787-481-8022x1977', 'Periodontist', 15, 'Mon, Sat', '2024-11-28 06:20:33.120105'), (10, 'Amy Woodward', 'elizabethrogers@example.com', '828.536.8841x36670', 'Periodontist', 32, 'Fri, Wed', '2024-11-28 06:20:33.135730')]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the connection to the vectordb\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM core_dentist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.utilities.sql_database.SQLDatabase at 0x1d055c3d0a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# print(\"Environment variables are loaded:\", load_dotenv())\n",
    "# print(\"test by reading a variable:\", os.getenv(\"OPENAI_API_TYPE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "print(\"success\")\n",
    "from openai import OpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "OPENAI_API_KEY =\"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\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# Create a chat completion request\n",
    "llm = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": str(\n",
    "        \"You are a helpful assistant\"\n",
    "    )},\n",
    "    {\"role\": \"user\", \"content\": str(\"hello\")}\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    n=1,\n",
    "    stop=[\"END\"],\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_9120\\1934595492.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000001AEA8050CE0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001AEA8052960> model_name='gpt-4' temperature=0.2 model_kwargs={} openai_api_key='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' openai_proxy=''\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"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\",\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.2\n",
    ")\n",
    " \n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "\n",
    "agent_executor = create_sql_agent(llm=llm, db=db, agent_type=\"openai-tools\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"How many appointment in 2024-11-27\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "Error executing command: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from pyprojroot import here\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from pyprojroot import here\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import warnings\n",
    "import os\n",
    "# from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.agent_toolkits.sql.base import SQLDatabaseToolkit\n",
    "from supabase import create_client, Client\n",
    "import asyncpg\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Set up the database path\n",
    "db_path = str(here(\"data\")) + \"/db.sqlite3\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"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\",\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# custom_prompt = \"\"\"\n",
    "# You are an SQL assistant. Your job is to generate SQL queries based on the user request. \n",
    "# The user may request SELECT, INSERT, UPDATE, or DELETE operations.\n",
    "\n",
    "# Examples:\n",
    "# - \"Create a new appointment for John Doe on 2024-12-10 at 10:00 AM for teeth cleaning with Dr. Smith.\" \n",
    "#   -> INSERT INTO core_appointment (id, appointment_date, status, notes, created_at, dentist_id, patient_id) VALUES ('John Doe', 'Teeth Cleaning', '2024-12-10', '10:00:00', (SELECT id FROM core_dentist WHERE name = 'Dr. Smith'));\n",
    "\n",
    "# - \"Update the appointment ID 1 to change the dentist to Dr. Jane.\"\n",
    "#   -> UPDATE core_appointment SET dentist_id = (SELECT id FROM core_dentist WHERE name = 'Dr. Jane') WHERE id = 1;\n",
    "\n",
    "# - \"Delete the appointment ID 1.\"\n",
    "#   -> DELETE FROM core_appointment WHERE id = 1;\n",
    "\n",
    "# Use the `agent_scratchpad` to show your reasoning or steps.\n",
    "\n",
    "# User Request: {input}\n",
    "# SQL Query: {agent_scratchpad}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "custom_prompt = \"\"\"\n",
    "You are an advanced SQL assistant for a dental clinic database. The database schema consists of the following models:\n",
    "\n",
    "1. **core_patient**:\n",
    "   - **Fields**: `id` (primary key), `name` (varchar), `email` (unique varchar), `phone_number` (varchar), `gender` (M/F/O), `date_of_birth` (date), `address` (text), `created_at` (datetime).\n",
    "   - **Description**: Stores information about patients.\n",
    "\n",
    "2. **core_dentist**:\n",
    "   - **Fields**: `id` (primary key), `name` (varchar), `email` (unique varchar), `phone_number` (varchar), `specialization` (choices: Orthodontist, Periodontist, Oral Surgeon, Pediatric Dentist, Prosthodontist, General Dentist), `years_of_experience` (integer), `availability_days` (varchar), `created_at` (datetime).\n",
    "   - **Description**: Stores dentist details, including specialization and availability.\n",
    "\n",
    "3. **core_appointment**:\n",
    "   - **Fields**: `id` (primary key), `patient_id` (foreign key to `core_patient`), `dentist_id` (foreign key to `core_dentist`), `appointment_date` (datetime), `status` (choices: Scheduled, Completed, Cancelled), `notes` (text), `created_at` (datetime).\n",
    "   - **Description**: Tracks appointments between patients and dentists.\n",
    "\n",
    "4. **core_treatment**:\n",
    "   - **Fields**: `id` (primary key), `appointment_id` (foreign key to `core_appointment`), `treatment_type` (choices: Cleaning, Filling, Root Canal, Extraction, Braces, Whitening, Implants), `description` (text), `cost` (decimal), `performed_on` (date).\n",
    "   - **Description**: Stores details of treatments performed during appointments.\n",
    "\n",
    "5. **core_payment**:\n",
    "   - **Fields**: `id` (primary key), `appointment_id` (foreign key to `core_appointment`), `amount` (decimal), `payment_date` (datetime), `payment_method` (choices: Cash, Credit Card, Insurance), `is_paid` (boolean).\n",
    "   - **Description**: Tracks payment details for each appointment.\n",
    "\n",
    "### Your Responsibilities:\n",
    "1. **Generate SQL queries** for the following operations:\n",
    "   - **Create**: Insert new records (e.g., patients, dentists, appointments, treatments, or payments).\n",
    "   - **Read**: Retrieve information (e.g., list all appointments for a patient, find all dentists by specialization).\n",
    "   - **Update**: Modify existing records (e.g., update appointment status, change patient contact details).\n",
    "   - **Delete**: Remove records (e.g., delete a canceled appointment).\n",
    "\n",
    "2. **Enforce Constraints**:\n",
    "   - Respect foreign key relationships.\n",
    "   - Avoid violating data types or field constraints (e.g., unique emails, valid choices for gender or specialization).\n",
    "\n",
    "3. **Use Examples as a Guide**:\n",
    "   #### Example 1: Create Operation\n",
    "   - **Input**: \"Create a new patient named 'John Doe' with email 'john@example.com', phone '1234567890', gender 'M', date of birth '1990-05-15', and address '123 Street Name'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     INSERT INTO core_patient (name, email, phone_number, gender, date_of_birth, address, created_at)\n",
    "     VALUES ('John Doe', 'john@example.com', '1234567890', 'M', '1990-05-15', '123 Street Name', NOW());\n",
    "     ```\n",
    "\n",
    "   #### Example 2: Read Operation\n",
    "   - **Input**: \"List all appointments for the patient 'John Doe'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     SELECT a.id, a.appointment_date, a.status, d.name AS dentist_name\n",
    "     FROM core_appointment a\n",
    "     JOIN core_patient p ON a.patient_id = p.id\n",
    "     JOIN core_dentist d ON a.dentist_id = d.id\n",
    "     WHERE p.name = 'John Doe';\n",
    "     ```\n",
    "\n",
    "   #### Example 3: Update Operation\n",
    "   - **Input**: \"Change the status of the appointment for 'John Doe' with 'Dr. Smith' on '2024-12-12' to 'Completed'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     UPDATE core_appointment\n",
    "     SET status = 'Completed'\n",
    "     WHERE patient_id = (SELECT id FROM core_patient WHERE name = 'John Doe')\n",
    "       AND dentist_id = (SELECT id FROM core_dentist WHERE name = 'Dr. Smith')\n",
    "       AND appointment_date = '2024-12-12 14:00:00';\n",
    "     ```\n",
    "\n",
    "   #### Example 4: Delete Operation\n",
    "   - **Input**: \"Delete the appointment for 'John Doe' with 'Dr. Smith' on '2024-12-12'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     DELETE FROM core_appointment\n",
    "     WHERE patient_id = (SELECT id FROM core_patient WHERE name = 'John Doe')\n",
    "       AND dentist_id = (SELECT id FROM core_dentist WHERE name = 'Dr. Smith')\n",
    "       AND appointment_date = '2024-12-12 14:00:00';\n",
    "     ```\n",
    "\n",
    "User  Request: {input}\n",
    "SQL Query: {agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Create the SQL agent\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    db=db,\n",
    "    agent_type=\"openai-tools\",\n",
    "    verbose=True,\n",
    "    prefix=None,  # Not needed when providing a full prompt\n",
    "    suffix=None,  # Not needed when providing a full prompt\n",
    "    format_instructions=None,  # Not needed when providing a full prompt\n",
    "    prompt=PromptTemplate(\n",
    "        template=custom_prompt,\n",
    "        input_variables=[\"input\", \"agent_scratchpad\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "def execute_sql_command(user_input):\n",
    "    \"\"\"\n",
    "    This function takes user input, generates a SQL query, and executes it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use the SQL agent to generate a SQL query based on user input\n",
    "        result = agent_executor.invoke({\"input\": user_input})\n",
    "\n",
    "        # Extract the SQL query from the result\n",
    "        generated_query = result['output']\n",
    "        \n",
    "        # Print the generated SQL query for debugging\n",
    "        print(\"Generated SQL Query:\", generated_query)\n",
    "\n",
    "        # Check if the generated query is valid SQL\n",
    "        if not generated_query.strip().upper().startswith((\"INSERT\", \"UPDATE\", \"DELETE\", \"SELECT\")):\n",
    "            raise ValueError(\"Generated output is not a valid SQL command.\")\n",
    "\n",
    "        # Use a session to execute the SQL command\n",
    "        with Session() as session:\n",
    "            # Handle SELECT statements to fetch results\n",
    "            if generated_query.strip().upper().startswith(\"SELECT\"):\n",
    "                query_result = session.execute(generated_query)\n",
    "                return query_result.fetchall()  # Return all results\n",
    "            else:\n",
    "                # If it's not a SELECT, assume it's an insert/update/delete\n",
    "                session.execute(generated_query)  # Execute the SQL command\n",
    "                session.commit()  # Commit the transaction\n",
    "                return \"Operation executed successfully.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing command: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example user prompts\n",
    "    user_input = input(\"Enter your command: \")\n",
    "    \n",
    "    # Execute the command and print results\n",
    "    results = execute_sql_command(user_input)\n",
    "    if results is not None:\n",
    "        print(\"Query Results:\", results)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"How many appointment in 2024-11-27 may i know the patient details\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Gloria smith paid or not?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"May i know the availability of dentist David Jacobson?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What kind of treatment to do for Lauren wise?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"May i know the availability days of dentist David Jacobson?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query_checker` with `{'query': \"INSERT INTO core_appointment (patient_id, dentist_id, appointment_date, status, created_at) VALUES ((SELECT id FROM core_patient WHERE name = 'sathyamoorthy' LIMIT 1), (SELECT id FROM core_dentist WHERE name = 'sibi narayanan' LIMIT 1), '2024-12-10 16:00:00', 'Scheduled', CURRENT_TIMESTAMP);\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mINSERT INTO core_appointment (patient_id, dentist_id, appointment_date, status, created_at) VALUES ((SELECT id FROM core_patient WHERE name = 'sathyamoorthy' LIMIT 1), (SELECT id FROM core_dentist WHERE name = 'sibi narayanan' LIMIT 1), '2024-12-10 16:00:00', 'Scheduled', CURRENT_TIMESTAMP);\u001b[0m\u001b[32;1m\u001b[1;3mThe SQL query to create a new appointment for Sathyamoorthy on 2024-12-10 at 4 PM with Sibi Narayanan is:\n",
      "\n",
      "```sql\n",
      "INSERT INTO core_appointment (patient_id, dentist_id, appointment_date, status, created_at) \n",
      "VALUES (\n",
      "  (SELECT id FROM core_patient WHERE name = 'sathyamoorthy' LIMIT 1), \n",
      "  (SELECT id FROM core_dentist WHERE name = 'sibi narayanan' LIMIT 1), \n",
      "  '2024-12-10 16:00:00', \n",
      "  'Scheduled', \n",
      "  CURRENT_TIMESTAMP\n",
      ");\n",
      "```\n",
      "\n",
      "This query will insert a new record into the `core_appointment` table. The `patient_id` and `dentist_id` are fetched from the `core_patient` and `core_dentist` tables respectively, using the provided names. The appointment date is set to '2024-12-10 16:00:00', the status is set to 'Scheduled', and the `created_at` timestamp is set to the current date and time.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "This is the out put of  {'input': 'Create a new appointment for sathyamoorthy on 2024-12-10 at 4 PM for tooth cleaning with sibi narayanan.', 'output': \"The SQL query to create a new appointment for Sathyamoorthy on 2024-12-10 at 4 PM with Sibi Narayanan is:\\n\\n```sql\\nINSERT INTO core_appointment (patient_id, dentist_id, appointment_date, status, created_at) \\nVALUES (\\n  (SELECT id FROM core_patient WHERE name = 'sathyamoorthy' LIMIT 1), \\n  (SELECT id FROM core_dentist WHERE name = 'sibi narayanan' LIMIT 1), \\n  '2024-12-10 16:00:00', \\n  'Scheduled', \\n  CURRENT_TIMESTAMP\\n);\\n```\\n\\nThis query will insert a new record into the `core_appointment` table. The `patient_id` and `dentist_id` are fetched from the `core_patient` and `core_dentist` tables respectively, using the provided names. The appointment date is set to '2024-12-10 16:00:00', the status is set to 'Scheduled', and the `created_at` timestamp is set to the current date and time.\"}\n",
      "SQL Query: INSERT INTO core_appointment (patient_id, dentist_id, appointment_date, status, created_at) \n",
      "VALUES (\n",
      "  (SELECT id FROM core_patient WHERE name = 'sathyamoorthy' LIMIT 1), \n",
      "  (SELECT id FROM core_dentist WHERE name = 'sibi narayanan' LIMIT 1), \n",
      "  '2024-12-10 16:00:00', \n",
      "  'Scheduled', \n",
      "  CURRENT_TIMESTAMP\n",
      ");\n",
      "Response from Mistral-7B:  appointment_date, appointment_type_id, appointment_status_id, created_at, updated_at) > VALUES (?, ?, ?, ?, NOW(), NOW());\\n```\">\n",
      "The SQL query provided does not have any syntax errors. Here is the corrected version for better readability:\n",
      "\n",
      "```sql\n",
      "INSERT INTO core_appointment (patient_id, appointment_date, appointment_type_id, appointment_status_id, created_at, updated_at)\n",
      "VALUES (?, ?, ?, ?, NOW(), NOW());\n",
      "```\n",
      "\n",
      "The backticks (`) around the table name `core_appointment` are not required, but they can be used for identifiers that are reserved words or contain special characters in MySQL. In this case, they are not necessary.\n",
      "\n",
      "The question marks (?) are placeholders for the values that will be supplied when the query is executed. The number of question marks should match the number of columns in the table.\n",
      "\n",
      "The `NOW()` function is used to provide the current date and time for the `created_at` and `updated_at` fields.\n",
      "An error occurred: NOT NULL constraint failed: core_appointment.patient_id\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.agent_toolkits.sql.base import SQLDatabaseToolkit\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_community.agent_toolkits.sql.base import SQLDatabaseToolkit\n",
    "import sqlite3\n",
    "# Customize the agent prompt for write operations\n",
    "# custom_prompt = \"\"\"\n",
    "# You are an SQL assistant. Your job is to generate SQL queries based on the user request. \n",
    "# The user may request SELECT, INSERT, UPDATE, or DELETE operations.\n",
    "\n",
    "# Examples:\n",
    "# - \"Create a new appointment for John Doe on 2024-12-10 at 10:00 AM for teeth cleaning with Dr. Smith.\" \n",
    "#   -> INSERT INTO core_appointment (id, appointment_date, status, notes, created_at, dentist_id, patient_id) VALUES ('John Doe', 'Teeth Cleaning', '2024-12-10', '10:00:00', (SELECT id FROM core_dentist WHERE name = 'Dr. Smith'));\n",
    "\n",
    "# - \"Update the appointment ID 1 to change the dentist to Dr. Jane.\"\n",
    "#   -> UPDATE core_appointment SET dentist_id = (SELECT id FROM core_dentist WHERE name = 'Dr. Jane') WHERE id = 1;\n",
    "\n",
    "# - \"Delete the appointment ID 1.\"\n",
    "#   -> DELETE FROM core_appointment WHERE id = 1;\n",
    "\n",
    "# Use the `agent_scratchpad` to show your reasoning or steps.\n",
    "\n",
    "# User Request: {input}\n",
    "# SQL Query: {agent_scratchpad}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# custom_prompt = \"\"\"\n",
    "# You are an advanced SQL assistant for a dental clinic database. The database schema consists of the following models:\n",
    "\n",
    "# 1. **core_patient**:\n",
    "# - **Fields**: `id` (primary key), `name` (varchar), `email` (unique varchar), `phone_number` (varchar), `gender` (M/F/O), `date_of_birth` (date), `address` (text), `created_at` (datetime).\n",
    "# - **Description**: Stores information about patients.\n",
    "\n",
    "# ### 2. **core_dentist**:\n",
    "# - **Fields**: `id` (primary key), `name` (varchar), `email` (unique varchar), `phone_number` (varchar), `specialization` (choices: Orthodontist, Periodontist, Oral Surgeon, Pediatric Dentist, Prosthodontist, General Dentist), `years_of_experience` (integer), `availability_days` (varchar), `created_at` (datetime).\n",
    "# - **Description**: Stores dentist details, including specialization and availability.\n",
    "\n",
    "# ### 3. **core_appointment**:\n",
    "# - **Fields**: `id` (primary key), `patient_id` (foreign key to `Patient`), `dentist_id` (foreign key to `Dentist`), `appointment_date` (datetime), `status` (choices: Scheduled, Completed, Cancelled), `notes` (text), `created_at` (datetime).\n",
    "# - **Description**: Tracks appointments between patients and dentists.\n",
    "\n",
    "# ### 4. **core_treatment**:\n",
    "# - **Fields**: `id` (primary key), `appointment_id` (foreign key to `Appointment`), `treatment_type` (choices: Cleaning, Filling, Root Canal, Extraction, Braces, Whitening, Implants), `description` (text), `cost` (decimal), `performed_on` (date).\n",
    "# - **Description**: Stores details of treatments performed during appointments.\n",
    "\n",
    "# ### 5. core_payment**:\n",
    "# - **Fields**: `id` (primary key), `appointment_id` (foreign key to `Appointment`), `amount` (decimal), `payment_date` (datetime), `payment_method` (choices: Cash, Credit Card, Insurance), `is_paid` (boolean).\n",
    "# - **Description**: Tracks payment details for each appointment.\n",
    "\n",
    "# ### Your Responsibilities:\n",
    "# 1. **Generate SQL queries** for the following operations:\n",
    "#    - **Create**: Insert new records (e.g., patients, dentists, appointments, treatments, or payments).\n",
    "#    - **Read**: Retrieve information (e.g., list all appointments for a patient, find all dentists by specialization).\n",
    "#    - **Update**: Modify existing records (e.g., update appointment status, change patient contact details).\n",
    "#    - **Delete**: Remove records (e.g., delete a canceled appointment).\n",
    "\n",
    "# 2. **Enforce Constraints**:\n",
    "#    - Respect foreign key relationships.\n",
    "#    - Avoid violating data types or field constraints (e.g., unique emails, valid choices for gender or specialization).\n",
    "\n",
    "# 3. **Use Examples as a Guide**:\n",
    "#    #### Example 1: Create Operation\n",
    "#    - **Input**: \"Create a new patient named 'John Doe' with email 'john@example.com', phone '1234567890', gender 'M', date of birth '1990-05-15', and address '123 Street Name'.\"\n",
    "#    - **Output**:\n",
    "#      ```sql\n",
    "#      INSERT INTO patient (name, email, phone_number, gender, date_of_birth, address, created_at)\n",
    "#      VALUES ('John Doe', 'john@example.com', '1234567890', 'M', '1990-05-15', '123 Street Name', NOW());\n",
    "#      ```\n",
    "\n",
    "#    #### Example 2: Read Operation\n",
    "#    - **Input**: \"List all appointments for the patient 'John Doe'.\"\n",
    "#    - **Output**:\n",
    "#      ```sql\n",
    "#      SELECT a.id, a.appointment_date, a.status, d.name AS dentist_name\n",
    "#      FROM appointment a\n",
    "#      JOIN patient p ON a.patient_id = p.id\n",
    "#      JOIN dentist d ON a.dentist_id = d.id\n",
    "#      WHERE p.name = 'John Doe';\n",
    "#      ```\n",
    "\n",
    "#    #### Example 3: Update Operation\n",
    "#    - **Input**: \"Change the status of the appointment for 'John Doe' with 'Dr. Smith' on '2024-12-12' to 'Completed'.\"\n",
    "#    - **Output**:\n",
    "#      ```sql\n",
    "#      UPDATE appointment\n",
    "#      SET status = 'Completed'\n",
    "#      WHERE patient_id = (SELECT id FROM patient WHERE name = 'John Doe')\n",
    "#        AND dentist_id = (SELECT id FROM dentist WHERE name = 'Dr. Smith')\n",
    "#        AND appointment_date = '2024-12-12 14:00:00';\n",
    "#      ```\n",
    "\n",
    "#    #### Example 4: Delete Operation\n",
    "#    - **Input**: \"Delete the appointment for 'John Doe' with 'Dr. Smith' on '2024-12-12'.\"\n",
    "#    - **Output**:\n",
    "#      ```sql\n",
    "#      DELETE FROM appointment\n",
    "#      WHERE patient_id = (SELECT id FROM patient WHERE name = 'John Doe')\n",
    "#        AND dentist_id = (SELECT id FROM dentist WHERE name = 'Dr. Smith')\n",
    "#        AND appointment_date = '2024-12-12 14:00:00';\n",
    "#      ```\n",
    "#     User Request: {input}\n",
    "#     SQL Query: {agent_scratchpad}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "custom_prompt = \"\"\"\n",
    "You are an advanced SQL assistant for a dental clinic database. The database schema consists of the following models:\n",
    "\n",
    "1. **core_patient**:\n",
    "- **Fields**: `id` (primary key), `name` (varchar), `email` (unique varchar), `phone_number` (varchar), `gender` (M/F/O), `date_of_birth` (date), `address` (text), `created_at` (datetime).\n",
    "- **Description**: Stores information about patients.\n",
    "\n",
    "### 2. **core_dentist**:\n",
    "- **Fields**: `id` (primary key), `name` (varchar), `email` (unique varchar), `phone_number` (varchar), `specialization` (choices: Orthodontist, Periodontist, Oral Surgeon, Pediatric Dentist, Prosthodontist, General Dentist), `years_of_experience` (integer), `availability_days` (varchar), `created_at` (datetime).\n",
    "- **Description**: Stores dentist details, including specialization and availability.\n",
    "\n",
    "### 3. **core_appointment**:\n",
    "- **Fields**: `id` (primary key), `patient_id` (foreign key to `Patient`), `dentist_id` (foreign key to `Dentist`), `appointment_date` (datetime), `status` (choices: Scheduled, Completed, Cancelled), `notes` (text), `created_at` (datetime).\n",
    "- **Description**: Tracks appointments between patients and dentists.\n",
    "\n",
    "### 4. **core_treatment**:\n",
    "- **Fields**: `id` (primary key), `appointment_id` (foreign key to `Appointment`), `treatment_type` (choices: Cleaning, Filling, Root Canal, Extraction, Braces, Whitening, Implants), `description` (text), `cost` (decimal), `performed_on` (date).\n",
    "- **Description**: Stores details of treatments performed during appointments.\n",
    "\n",
    "### 5. **core_payment**:\n",
    "- **Fields**: `id` (primary key), `appointment_id` (foreign key to `Appointment`), `amount` (decimal), `payment_date` (datetime), `payment_method` (choices: Cash, Credit Card, Insurance), `is_paid` (boolean).\n",
    "- **Description**: Tracks payment details for each appointment.\n",
    "\n",
    "### Your Responsibilities:\n",
    "1. **Generate SQL queries** for the following operations:\n",
    "   - **Create**: Insert new records (e.g., patients, dentists, appointments, treatments, or payments).\n",
    "   - **Read**: Retrieve information (e.g., list all appointments for a patient, find all dentists by specialization).\n",
    "   - **Update**: Modify existing records (e.g., update appointment status, change patient contact details).\n",
    "   - **Delete**: Remove records (e.g., delete a canceled appointment).\n",
    "\n",
    "2. **Enforce Constraints**:\n",
    "   - Respect foreign key relationships.\n",
    "   - Avoid violating data types or field constraints (e.g., unique emails, valid choices for gender or specialization).\n",
    "\n",
    "3. **Handle Errors**:\n",
    "   - If the query encounters errors like `NOT NULL constraint failed`, ensure that the foreign key subqueries for `patient_id` and `dentist_id` return valid records by adding `LIMIT 1` to ensure only one row is returned. \n",
    "   - If the `NOW()` function is not supported in the current SQL environment, replace it with `CURRENT_TIMESTAMP` or a fixed timestamp for `created_at`.\n",
    "\n",
    "4. **Use Examples as a Guide**:\n",
    "   #### Example 1: Create Operation\n",
    "   - **Input**: \"Create a new patient named 'John Doe' with email 'john@example.com', phone '1234567890', gender 'M', date of birth '1990-05-15', and address '123 Street Name'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     INSERT INTO core_patient (name, email, phone_number, gender, date_of_birth, address, created_at)\n",
    "     VALUES ('John Doe', 'john@example.com', '1234567890', 'M', '1990-05-15', '123 Street Name', CURRENT_TIMESTAMP);\n",
    "     ```\n",
    "\n",
    "   #### Example 2: Read Operation\n",
    "   - **Input**: \"List all appointments for the patient 'John Doe'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     SELECT a.id, a.appointment_date, a.status, d.name AS dentist_name\n",
    "     FROM core_appointment a\n",
    "     JOIN core_patient p ON a.patient_id = p.id\n",
    "     JOIN core_dentist d ON a.dentist_id = d.id\n",
    "     WHERE p.name = 'John Doe';\n",
    "     ```\n",
    "\n",
    "   #### Example 3: Update Operation\n",
    "   - **Input**: \"Change the status of the appointment for 'John Doe' with 'Dr. Smith' on '2024-12-12' to 'Completed'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     UPDATE core_appointment\n",
    "     SET status = 'Completed'\n",
    "     WHERE patient_id = (SELECT id FROM core_patient WHERE name = 'John Doe' LIMIT 1)\n",
    "       AND dentist_id = (SELECT id FROM core_dentist WHERE name = 'Dr. Smith' LIMIT 1)\n",
    "       AND appointment_date = '2024-12-12 14:00:00';\n",
    "     ```\n",
    "\n",
    "   #### Example 4: Delete Operation\n",
    "   - **Input**: \"Delete the appointment for 'John Doe' with 'Dr. Smith' on '2024-12-12'.\"\n",
    "   - **Output**:\n",
    "     ```sql\n",
    "     DELETE FROM core_appointment\n",
    "     WHERE patient_id = (SELECT id FROM core_patient WHERE name = 'John Doe' LIMIT 1)\n",
    "       AND dentist_id = (SELECT id FROM core_dentist WHERE name = 'Dr. Smith' LIMIT 1)\n",
    "       AND appointment_date = '2024-12-12 14:00:00';\n",
    "     ```\n",
    "\n",
    "### Guidelines:\n",
    "- **Avoid NULLs**: Ensure that foreign keys (`patient_id`, `dentist_id`) always refer to valid existing records. Add proper error handling if either subquery does not return a result.\n",
    "- **Datetime Handling**: If `NOW()` is unsupported, use `CURRENT_TIMESTAMP` or provide a fixed value for `created_at`.\n",
    "\n",
    "User Request: {input}\n",
    "SQL Query: {agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "db_path = str(here(\"data\")) + \"/db.sqlite3\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(llm=llm, db=db)\n",
    "\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import os\n",
    "# Hugging Face API Key and Endpoint Setup\n",
    "sec_key = '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'\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = sec_key\n",
    "\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Hugging Face endpoint repository ID\n",
    "sql_llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=2000, temperature=0.7, token=sec_key)\n",
    "\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    db=db,\n",
    "    agent_type=\"openai-tools\",\n",
    "    verbose=True,\n",
    "    prefix=None,  # Not needed when providing a full prompt\n",
    "    suffix=None,  # Not needed when providing a full prompt\n",
    "    format_instructions=None,  # Not needed when providing a full prompt\n",
    "    prompt=PromptTemplate(\n",
    "        template=custom_prompt,\n",
    "        input_variables=[\"input\", \"agent_scratchpad\"]\n",
    "    )\n",
    ") \n",
    "#\n",
    "result = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Create a new appointment for sathyamoorthy on 2024-12-10 at 4 PM for tooth cleaning with sibi narayanan.\"\n",
    "\n",
    "    }\n",
    ")\n",
    "print(\"This is the out put of \",result)\n",
    "\n",
    "\n",
    "output = result['output']\n",
    "\n",
    "# Extract SQL query from the output string\n",
    "import re\n",
    "\n",
    "# Regex to find SQL queries between ```sql and ```\n",
    "sql_query = re.search(r\"```sql\\n(.*?)\\n```\", output, re.DOTALL)\n",
    "\n",
    "# If a match is found, print the SQL query\n",
    "if sql_query:\n",
    "    print(\"SQL Query:\", sql_query.group(1))\n",
    "\n",
    "    prompt = f\"Check if the following SQL query has any syntax errors and return the corrected version if necessary:\\n{sql_query}\"\n",
    "\n",
    "    response = sql_llm.invoke(prompt)\n",
    "\n",
    "    # Print the response from the model\n",
    "    print(\"Response from Mistral-7B:\", response)\n",
    "\n",
    "    connection = None  # Initialize connection to None\n",
    "    try:\n",
    "        connection = sqlite3.connect(db_path)  # Connect to the database\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        cursor.execute(sql_query.group(1))  # Execute the SQL query\n",
    "        connection.commit()  # Commit the transaction\n",
    "        print('SQL Query successfully created')\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "      \n",
    "    finally:\n",
    "        if connection:  # Check if connection was established before closing\n",
    "            connection.close()  \n",
    "\n",
    "else:\n",
    "    print(\"No SQL query found.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Change the status of the appointment for 'John Doe' with 'Dr. Alice' on '2024-12-12' to 'Completed'.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New workflow of Chatbot interaction.\n",
    "\n",
    "from langchain.utilities import SQLDatabase\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    pipeline, \n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    ")\n",
    "\n",
    "import sqlparse\n",
    "\n",
    "\n",
    "class WorkFlowProcessor:\n",
    "\n",
    "    def __init__(self, db_path):\n",
    "\n",
    "        self.intent_model = AutoModelForSequenceClassification(\"bert-base-uncased\")\n",
    "        self.intent_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        self.category_classifier = pipeline(\"text-classification\", model=\"roberta-base\")\n",
    "\n",
    "        self.data_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "        self.data_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "        # Database Configuration\n",
    "\n",
    "        self.db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "        \n",
    "\n",
    "    def detect_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Replace with your SQLite database path\u001b[39;00m\n\u001b[0;32m    114\u001b[0m db_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb.sqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 115\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mWorkflowProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a new appointment for John Doe\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m result \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mprocess_request(user_input)\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36mWorkflowProcessor.__init__\u001b[1;34m(self, db_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Database Configuration\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m SQLDatabase\u001b[38;5;241m.\u001b[39mfrom_uri(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\surya\\Muscle Mind\\LLM project\\.venv2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1637\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1637\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\surya\\Muscle Mind\\LLM project\\.venv2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1625\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1623\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    ")\n",
    "import sqlparse\n",
    "\n",
    "class WorkflowProcessor:\n",
    "    def __init__(self, db_path):\n",
    "        # Step 1: Load Models\n",
    "        self.intent_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "        self.intent_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        self.category_classifier = pipeline(\"text-classification\", model=\"roberta-base\")\n",
    "        \n",
    "        self.data_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "        self.data_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "        \n",
    "        # Database Configuration\n",
    "        self.db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "\n",
    "    def detect_intent(self, user_input):\n",
    "        \"\"\"Step 1: Detect Intent\"\"\"\n",
    "        inputs = self.intent_tokenizer(user_input, return_tensors=\"pt\")\n",
    "        outputs = self.intent_model(**inputs)\n",
    "        intent = outputs.logits.argmax(dim=-1).item()\n",
    "        return intent\n",
    "\n",
    "    def categorize_prompt(self, prompt):\n",
    "        \"\"\"Step 2: Categorize Prompt\"\"\"\n",
    "        result = self.category_classifier(prompt)\n",
    "        return result[0][\"label\"]\n",
    "\n",
    "    def collect_data(self, prompt):\n",
    "        \"\"\"Step 3: Collect Missing Information\"\"\"\n",
    "        input_text = f\"Collect data: {prompt}\"\n",
    "        inputs = self.data_tokenizer(input_text, return_tensors=\"pt\")\n",
    "        outputs = self.data_model.generate(inputs[\"input_ids\"], max_length=50)\n",
    "        return self.data_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    def validate_database(self, query):\n",
    "        \"\"\"Step 4: Validate Against Database\"\"\"\n",
    "        try:\n",
    "            result = self.db.run(query)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "    def generate_sql(self, intent, data):\n",
    "        \"\"\"Step 5: Generate SQL Query\"\"\"\n",
    "        if intent == \"CREATE\":\n",
    "            return f\"INSERT INTO appointments (name, date, dentist, notes) VALUES ('{data['name']}', '{data['date']}', '{data['dentist']}', '{data['notes']}');\"\n",
    "        elif intent == \"READ\":\n",
    "            return f\"SELECT * FROM appointments WHERE name='{data['name']}';\"\n",
    "        # Add additional cases as needed\n",
    "\n",
    "    def validate_sql(self, sql_query):\n",
    "        \"\"\"Step 6: Validate SQL Query\"\"\"\n",
    "        try:\n",
    "            parsed = sqlparse.parse(sql_query)\n",
    "            return len(parsed) > 0\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def execute_query(self, query):\n",
    "        \"\"\"Step 7: Execute SQL Query\"\"\"\n",
    "        try:\n",
    "            result = self.db.run(query)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "    def generate_response(self, action, status):\n",
    "        \"\"\"Step 8: Generate User-Friendly Response\"\"\"\n",
    "        return f\"Your {action.lower()} action was {status}.\"\n",
    "\n",
    "    def process_request(self, user_input):\n",
    "        \"\"\"Main Workflow Orchestrator\"\"\"\n",
    "        try:\n",
    "            # Step 1: Detect Intent\n",
    "            intent = self.detect_intent(user_input)\n",
    "            \n",
    "            # Step 2: Categorize Prompt\n",
    "            category = self.categorize_prompt(user_input)\n",
    "            \n",
    "            # Step 3: Collect Missing Data\n",
    "            data = self.collect_data(user_input)\n",
    "            \n",
    "            # Step 4: Generate SQL Query\n",
    "            sql_query = self.generate_sql(intent, eval(data))  # Assuming data is returned as a dict-like string\n",
    "            \n",
    "            # Step 5: Validate SQL Query\n",
    "            if self.validate_sql(sql_query):\n",
    "                # Step 6: Execute SQL Query\n",
    "                db_status = self.execute_query(sql_query)\n",
    "                \n",
    "                # Step 7: Generate Response\n",
    "                response = self.generate_response(category, \"successful\" if db_status else \"failed\")\n",
    "                return {\"response\": response}\n",
    "            else:\n",
    "                return {\"error\": \"Invalid SQL query\"}\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Replace with your SQLite database path\n",
    "    db_path = str(Path(\"data\") / \"db.sqlite3\")\n",
    "    processor = WorkflowProcessor(db_path)\n",
    "    \n",
    "    user_input = \"Create a new appointment for John Doe\"\n",
    "    result = processor.process_request(user_input)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 116\u001b[0m\n\u001b[0;32m    109\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[0;32m    110\u001b[0m     openai_api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-proj-_gccWLf2H5YRh3fjHwzyILWYxlgdHInEsuxQsU86G6pz1-1EB-2uw9ZbQtjmiKvOsPvXuwekXZT3BlbkFJJo4fsF0UCSa90szq0XC8RiCNiPtDSDGpzIcVl6c1jmYuBQA9q764I9s0bfGP11pix30W5o3-0A\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    112\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m    113\u001b[0m )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Initialize the processor\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mWorkflowProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Example user request\u001b[39;00m\n\u001b[0;32m    119\u001b[0m user_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a new appointment for sathyamoorthy on 2024-12-10 at 4 PM for tooth cleaning with sibi narayanan.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[10], line 23\u001b[0m, in \u001b[0;36mWorkflowProcessor.__init__\u001b[1;34m(self, db_path, llm)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-classification\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Database Configuration\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m SQLDatabase\u001b[38;5;241m.\u001b[39mfrom_uri(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\surya\\Muscle Mind\\LLM project\\.venv2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1637\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1637\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\surya\\Muscle Mind\\LLM project\\.venv2\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1625\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1623\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.agent_toolkits.sql.base import SQLDatabaseToolkit\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "class WorkflowProcessor:\n",
    "    def __init__(self, db_path, llm):\n",
    "        # Step 1: Load Models\n",
    "        self.intent_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "        self.intent_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        self.category_classifier = pipeline(\"text-classification\", model=\"roberta-base\")\n",
    "        \n",
    "        self.data_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "        self.data_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "        \n",
    "        # Database Configuration\n",
    "        self.db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "        self.llm = llm  # Provide your LLM (e.g., OpenAI or Hugging Face)\n",
    "\n",
    "        # Custom SQL Agent\n",
    "        self.custom_prompt = \"\"\"\n",
    "        You are an advanced SQL assistant for a dental clinic database...\n",
    "        User Request: {input}\n",
    "        SQL Query: {agent_scratchpad}\n",
    "        \"\"\"\n",
    "        self.toolkit = SQLDatabaseToolkit(llm=self.llm, db=self.db)\n",
    "        self.agent_executor = create_sql_agent(\n",
    "            llm=self.llm,\n",
    "            db=self.db,\n",
    "            agent_type=\"openai-tools\",\n",
    "            verbose=True,\n",
    "            prefix=None,\n",
    "            suffix=None,\n",
    "            format_instructions=None,\n",
    "            prompt=PromptTemplate(\n",
    "                template=self.custom_prompt,\n",
    "                input_variables=[\"input\", \"agent_scratchpad\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def detect_intent(self, user_input):\n",
    "        \"\"\"Step 1: Detect Intent\"\"\"\n",
    "        inputs = self.intent_tokenizer(user_input, return_tensors=\"pt\")\n",
    "        outputs = self.intent_model(**inputs)\n",
    "        intent = outputs.logits.argmax(dim=-1).item()\n",
    "        return intent\n",
    "\n",
    "    def categorize_prompt(self, prompt):\n",
    "        \"\"\"Step 2: Categorize Prompt\"\"\"\n",
    "        result = self.category_classifier(prompt)\n",
    "        return result[0][\"label\"]\n",
    "\n",
    "    def collect_data(self, prompt):\n",
    "        \"\"\"Step 3: Collect Missing Information\"\"\"\n",
    "        input_text = f\"Collect data: {prompt}\"\n",
    "        inputs = self.data_tokenizer(input_text, return_tensors=\"pt\")\n",
    "        outputs = self.data_model.generate(inputs[\"input_ids\"], max_length=50)\n",
    "        return self.data_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    def execute_agent(self, user_request):\n",
    "        \"\"\"Step 4: Execute SQL Agent\"\"\"\n",
    "        try:\n",
    "            response = self.agent_executor.invoke({\"input\": user_request})\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return str(e)\n",
    "\n",
    "    def process_request(self, user_input):\n",
    "        \"\"\"Main Workflow Orchestrator\"\"\"\n",
    "        try:\n",
    "            # Step 1: Detect Intent\n",
    "            intent = self.detect_intent(user_input)\n",
    "            \n",
    "            # Step 2: Categorize Prompt\n",
    "            category = self.categorize_prompt(user_input)\n",
    "            \n",
    "            # Step 3: Collect Missing Data\n",
    "            missing_data = self.collect_data(user_input)\n",
    "            \n",
    "            # Step 4: Execute Agent with the complete prompt\n",
    "            agent_result = self.execute_agent(user_input)\n",
    "            \n",
    "            # Step 5: Generate Response\n",
    "            return {\"intent\": intent, \"category\": category, \"agent_result\": agent_result}\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    from langchain.chat_models import ChatOpenAI  # Replace with your LLM initialization\n",
    "\n",
    "    # Replace with your database path\n",
    "    db_path = str(Path(\"data\") / \"db.sqlite3\")\n",
    "    \n",
    "    # Example LLM (can be OpenAI or any other compatible model)\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=\"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\",\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    # Initialize the processor\n",
    "    processor = WorkflowProcessor(db_path, llm)\n",
    "    \n",
    "    # Example user request\n",
    "    user_request = \"Create a new appointment for sathyamoorthy on 2024-12-10 at 4 PM for tooth cleaning with sibi narayanan.\"\n",
    "    result = processor.process_request(user_request)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
